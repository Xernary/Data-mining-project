#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training) # cp = 0.0001
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
pt1.cart$cptable
plotcp(pt1.cart)
#cp = “value” is the assigned a numeric value that will determine how deep you want your tree to grow.
#The smaller the value (closer to 0), the larger the tree. The default value is 0.01, which will render a very pruned tree.
pt1.cart <- rpart(Class ~ ., data = pt1.training) # cp = 0.0001
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training) # cp = 0.0001
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training) # cp = 0.0001
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
breast.cart <- rpart(Class ~ ., data = breast.training)
#Stampo l'albero decisionale ottenuto in forma testuale
breast.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(breast.cart)
#Visualizzo graficamente l'albero
rpart.plot(breast.cart)
#Visualizzo graficamente l'albero, nascondendo le etichette di maggioranza nei nodi interni,
#mostrando la percentuale di benigni e maligni in ogni nodo,
#oltre alla percentuale di tuple del training set associato ad ogni nodo.
rpart.plot(breast.cart, type = 0, extra = 104)
#Pruning dell'albero:
#CART utilizza il cost-complexity pruning (CP) e memorizza il cost-complexity pruning per vari alberi
#Ogni albero ? ottenuto facendo un certo numero di splitting.
#Normalmente CART considera l'albero con costo CP minimo
#Proviamo a fare pruning sull'albero generando un albero con costo CP pi? alto ma sempre accettabile
#Accettabile significa con un errore relativo <= 0.20
#Le informazioni sul costo CP in funzione del numero di splitting sono contenute nella CP table
breast.cart$cptable
#In alternativa possiamo usare la funzione plotcp per visualizzare l'errore relativo in
#funzione del costo CP
plotcp(breast.cart)
breast.cart <- rpart(Class ~ ., data = breast.training)
#Stampo l'albero decisionale ottenuto in forma testuale
breast.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(breast.cart)
#Visualizzo graficamente l'albero
rpart.plot(breast.cart)
#Visualizzo graficamente l'albero, nascondendo le etichette di maggioranza nei nodi interni,
#mostrando la percentuale di benigni e maligni in ogni nodo,
#oltre alla percentuale di tuple del training set associato ad ogni nodo.
rpart.plot(breast.cart, type = 0, extra = 104)
#Pruning dell'albero:
#CART utilizza il cost-complexity pruning (CP) e memorizza il cost-complexity pruning per vari alberi
#Ogni albero ? ottenuto facendo un certo numero di splitting.
#Normalmente CART considera l'albero con costo CP minimo
#Proviamo a fare pruning sull'albero generando un albero con costo CP pi? alto ma sempre accettabile
#Accettabile significa con un errore relativo <= 0.20
#Le informazioni sul costo CP in funzione del numero di splitting sono contenute nella CP table
breast.cart$cptable
#In alternativa possiamo usare la funzione plotcp per visualizzare l'errore relativo in
#funzione del costo CP
plotcp(breast.cart)
breast.cart <- rpart(Class ~ ., data = breast.training)
#Stampo l'albero decisionale ottenuto in forma testuale
breast.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(breast.cart)
#Visualizzo graficamente l'albero
rpart.plot(breast.cart)
#Visualizzo graficamente l'albero, nascondendo le etichette di maggioranza nei nodi interni,
#mostrando la percentuale di benigni e maligni in ogni nodo,
#oltre alla percentuale di tuple del training set associato ad ogni nodo.
rpart.plot(breast.cart, type = 0, extra = 104)
#Pruning dell'albero:
#CART utilizza il cost-complexity pruning (CP) e memorizza il cost-complexity pruning per vari alberi
#Ogni albero ? ottenuto facendo un certo numero di splitting.
#Normalmente CART considera l'albero con costo CP minimo
#Proviamo a fare pruning sull'albero generando un albero con costo CP pi? alto ma sempre accettabile
#Accettabile significa con un errore relativo <= 0.20
#Le informazioni sul costo CP in funzione del numero di splitting sono contenute nella CP table
breast.cart$cptable
#In alternativa possiamo usare la funzione plotcp per visualizzare l'errore relativo in
#funzione del costo CP
plotcp(breast.cart)
breast.cart <- rpart(Class ~ ., data = breast.training)
#Stampo l'albero decisionale ottenuto in forma testuale
breast.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(breast.cart)
#Visualizzo graficamente l'albero
rpart.plot(breast.cart)
#Visualizzo graficamente l'albero, nascondendo le etichette di maggioranza nei nodi interni,
#mostrando la percentuale di benigni e maligni in ogni nodo,
#oltre alla percentuale di tuple del training set associato ad ogni nodo.
rpart.plot(breast.cart, type = 0, extra = 104)
#Pruning dell'albero:
#CART utilizza il cost-complexity pruning (CP) e memorizza il cost-complexity pruning per vari alberi
#Ogni albero ? ottenuto facendo un certo numero di splitting.
#Normalmente CART considera l'albero con costo CP minimo
#Proviamo a fare pruning sull'albero generando un albero con costo CP pi? alto ma sempre accettabile
#Accettabile significa con un errore relativo <= 0.20
#Le informazioni sul costo CP in funzione del numero di splitting sono contenute nella CP table
breast.cart$cptable
#In alternativa possiamo usare la funzione plotcp per visualizzare l'errore relativo in
#funzione del costo CP
plotcp(breast.cart)
breast.cart <- rpart(Class ~ ., data = breast.training)
#Stampo l'albero decisionale ottenuto in forma testuale
breast.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(breast.cart)
#Visualizzo graficamente l'albero
rpart.plot(breast.cart)
#Visualizzo graficamente l'albero, nascondendo le etichette di maggioranza nei nodi interni,
#mostrando la percentuale di benigni e maligni in ogni nodo,
#oltre alla percentuale di tuple del training set associato ad ogni nodo.
rpart.plot(breast.cart, type = 0, extra = 104)
#Pruning dell'albero:
#CART utilizza il cost-complexity pruning (CP) e memorizza il cost-complexity pruning per vari alberi
#Ogni albero ? ottenuto facendo un certo numero di splitting.
#Normalmente CART considera l'albero con costo CP minimo
#Proviamo a fare pruning sull'albero generando un albero con costo CP pi? alto ma sempre accettabile
#Accettabile significa con un errore relativo <= 0.20
#Le informazioni sul costo CP in funzione del numero di splitting sono contenute nella CP table
breast.cart$cptable
#In alternativa possiamo usare la funzione plotcp per visualizzare l'errore relativo in
#funzione del costo CP
plotcp(breast.cart)
breast.cart <- rpart(Class ~ ., data = breast.training)
#Stampo l'albero decisionale ottenuto in forma testuale
breast.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(breast.cart)
#Visualizzo graficamente l'albero
rpart.plot(breast.cart)
#Visualizzo graficamente l'albero, nascondendo le etichette di maggioranza nei nodi interni,
#mostrando la percentuale di benigni e maligni in ogni nodo,
#oltre alla percentuale di tuple del training set associato ad ogni nodo.
rpart.plot(breast.cart, type = 0, extra = 104)
#Pruning dell'albero:
#CART utilizza il cost-complexity pruning (CP) e memorizza il cost-complexity pruning per vari alberi
#Ogni albero ? ottenuto facendo un certo numero di splitting.
#Normalmente CART considera l'albero con costo CP minimo
#Proviamo a fare pruning sull'albero generando un albero con costo CP pi? alto ma sempre accettabile
#Accettabile significa con un errore relativo <= 0.20
#Le informazioni sul costo CP in funzione del numero di splitting sono contenute nella CP table
breast.cart$cptable
#In alternativa possiamo usare la funzione plotcp per visualizzare l'errore relativo in
#funzione del costo CP
plotcp(breast.cart)
breast.cart <- rpart(Class ~ ., data = breast.training)
#Stampo l'albero decisionale ottenuto in forma testuale
breast.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(breast.cart)
#Visualizzo graficamente l'albero
rpart.plot(breast.cart)
#Visualizzo graficamente l'albero, nascondendo le etichette di maggioranza nei nodi interni,
#mostrando la percentuale di benigni e maligni in ogni nodo,
#oltre alla percentuale di tuple del training set associato ad ogni nodo.
rpart.plot(breast.cart, type = 0, extra = 104)
#Pruning dell'albero:
#CART utilizza il cost-complexity pruning (CP) e memorizza il cost-complexity pruning per vari alberi
#Ogni albero ? ottenuto facendo un certo numero di splitting.
#Normalmente CART considera l'albero con costo CP minimo
#Proviamo a fare pruning sull'albero generando un albero con costo CP pi? alto ma sempre accettabile
#Accettabile significa con un errore relativo <= 0.20
#Le informazioni sul costo CP in funzione del numero di splitting sono contenute nella CP table
breast.cart$cptable
#In alternativa possiamo usare la funzione plotcp per visualizzare l'errore relativo in
#funzione del costo CP
plotcp(breast.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.0001)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.0001)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.0001)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.0001)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.0001)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
breast.cart <- rpart(Class ~ ., data = breast.training)
#Stampo l'albero decisionale ottenuto in forma testuale
breast.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(breast.cart)
#Visualizzo graficamente l'albero
rpart.plot(breast.cart)
#Visualizzo graficamente l'albero, nascondendo le etichette di maggioranza nei nodi interni,
#mostrando la percentuale di benigni e maligni in ogni nodo,
#oltre alla percentuale di tuple del training set associato ad ogni nodo.
rpart.plot(breast.cart, type = 0, extra = 104)
#Pruning dell'albero:
#CART utilizza il cost-complexity pruning (CP) e memorizza il cost-complexity pruning per vari alberi
#Ogni albero ? ottenuto facendo un certo numero di splitting.
#Normalmente CART considera l'albero con costo CP minimo
#Proviamo a fare pruning sull'albero generando un albero con costo CP pi? alto ma sempre accettabile
#Accettabile significa con un errore relativo <= 0.20
#Le informazioni sul costo CP in funzione del numero di splitting sono contenute nella CP table
breast.cart$cptable
#In alternativa possiamo usare la funzione plotcp per visualizzare l'errore relativo in
#funzione del costo CP
plotcp(breast.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.001)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.005)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.005)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.006)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.007)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.008)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
#The smaller the value (closer to 0), the larger the tree. The default value is 0.01, which will render a very pruned tree.
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.009)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.01)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.001)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.0001)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.00001)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
pt1.cart <- rpart(Class ~ ., data = pt1.training,  cp = 0.00001)
#Stampo l'albero decisionale ottenuto in forma testuale
pt1.cart
#Per avere maggiori informazioni pi? accurate si pu? usare il metodo "printcp"
#che mostra anche il cost-complexity pruning (CP)
#nsplit ? il numero di split necessari per arrivare ad un nodo dell'albero
#relerror ? l'errore relativo
#xerror e xstd sono media e deviazione standard del cross-validation error
#(rpart effettua al suo interno una cross-validation)
printcp(pt1.cart)
rpart.plot(pt1.cart)
rpart.plot(pt1.cart, type = 0, extra = 104)
pt1.cart$cptable
plotcp(pt1.cart)
